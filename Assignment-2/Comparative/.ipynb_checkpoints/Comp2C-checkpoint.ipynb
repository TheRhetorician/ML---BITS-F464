{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "biblical-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "desirable-mapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity',\n",
       "       'ConvexArea', 'EquivDiameter', 'Extent', 'Perimeter', 'Roundness',\n",
       "       'AspectRation', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset_comb.csv\")\n",
    "df = df.sample(frac = 1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "equipped-thompson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jasmine    9985\n",
       "Gonen      8200\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['id'], axis = 1)\n",
    "df['Class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hourly-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jasmine - 0 , Gonen - 1\n",
    "for column in df.columns:\n",
    "    if column!='Class':\n",
    "        colmax = df[column].max()\n",
    "        colmin = df[column].min()\n",
    "        for val in df[column]:\n",
    "            val1 = (colmax - val)/(colmax - colmin)\n",
    "            df[column] = df[column].replace(val, val1)\n",
    "    elif column == 'Class':\n",
    "        for val in df[column]:\n",
    "            if val == 'jasmine':\n",
    "                df[column] = df[column].replace(val, 0)\n",
    "            elif val == 'Gonen':\n",
    "                df[column] = df[column].replace(val, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "upper-chancellor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18185, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.to_numpy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "later-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_g = np.array_split(data, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "blessed-cache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9807544264819091, 0.9799846035411856, 0.9842186297151655, 0.9807544264819091, 0.9795996920708238, 0.9861431870669746, 0.9845976126299576]\n",
      "[0.9826778725861295, 0.9828061846410471, 0.9819721562840829, 0.9825495605312119, 0.9828061846410471, 0.9818438442291654, 0.9821016166281755]\n",
      "Mean accuracy for test set =  0.9822932254268465\n",
      "Mean accuracy for train set =  0.9823939170772656\n"
     ]
    }
   ],
   "source": [
    "# FLD\n",
    "\n",
    "accuracy_fl_test = []\n",
    "accuracy_fl_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:      #creating training dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:      #creating testing dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "                \n",
    "    #convert into array\n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    #importing model from sklearn\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    #predict class\n",
    "    test_pred_y_fl = clf.predict(test_data_xn)\n",
    "    train_pred_y_fl = clf.predict(train_data_xn)\n",
    "    \n",
    "    #calculating and appending accuracies\n",
    "    acc1_fl = accuracy_score(test_data_yn, test_pred_y_fl)\n",
    "    accuracy_fl_test.append(acc1_fl)\n",
    "    \n",
    "    acc2_fl = accuracy_score(train_data_yn, train_pred_y_fl)\n",
    "    accuracy_fl_train.append(acc2_fl)\n",
    "\n",
    "print(accuracy_fl_test)\n",
    "print(accuracy_fl_train)\n",
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_fl_test))\n",
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_fl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "worldwide-luxury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9869130100076983, 0.985373364126251, 0.9907621247113164, 0.9757505773672055, 0.9795996920708238, 0.9861431870669746, 0.9896033885252215]\n",
      "[0.9876178867004555, 0.9868480143709502, 0.9876178867004555, 0.9782511066914736, 0.9792134471033553, 0.9838326810803875, 0.9857582755966128]\n",
      "Mean accuracy for test set =  0.9848779062679273\n",
      "Mean accuracy for train set =  0.9841627568919558\n"
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "\n",
    "accuracy_lp_test = []\n",
    "accuracy_lp_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:      #creating training dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:      #creating testing dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "\n",
    "    #convert into array  \n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    #importing model from sklearn\n",
    "    clf = Perceptron(tol = 1e-3, random_state=0)\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    #predict class\n",
    "    test_pred_y_lp = clf.predict(test_data_xn)\n",
    "    train_pred_y_lp = clf.predict(train_data_xn)\n",
    "    \n",
    "    #calculating and appending accuracies\n",
    "    acc1_lp = accuracy_score(test_data_yn, test_pred_y_lp)\n",
    "    accuracy_lp_test.append(acc1_lp)\n",
    "    \n",
    "    acc2_lp = accuracy_score(train_data_yn, train_pred_y_lp)\n",
    "    accuracy_lp_train.append(acc2_lp)\n",
    "\n",
    "    \n",
    "print(accuracy_lp_test)\n",
    "print(accuracy_lp_train)\n",
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_lp_test))\n",
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_lp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "remarkable-ethics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9838337182448037, 0.985373364126251, 0.9876828329484219, 0.9849884526558892, 0.9795996920708238, 0.9872979214780601, 0.9876780901039661]\n",
      "[0.9853724257393982, 0.9856932058766921, 0.9853082697119394, 0.9856932058766921, 0.9856290498492334, 0.985436581766857, 0.985245060302797]\n",
      "Mean accuracy for test set =  0.9852077245183165\n",
      "Mean accuracy for train set =  0.9854825427319441\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "accuracy_nb_test = []\n",
    "accuracy_nb_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:      #creating training dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:      #creating testing dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "       \n",
    "    #convert into array         \n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    #importing model from sklearn\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    #predict class\n",
    "    test_pred_y_nb = clf.predict(test_data_xn)\n",
    "    train_pred_y_nb = clf.predict(train_data_xn)\n",
    "\n",
    "    #calculating and appending accuracies\n",
    "    acc1_nb = accuracy_score(test_data_yn, test_pred_y_nb)\n",
    "    accuracy_nb_test.append(acc1_nb)\n",
    "    \n",
    "    acc2_nb = accuracy_score(train_data_yn, train_pred_y_nb)\n",
    "    accuracy_nb_train.append(acc2_nb)\n",
    "\n",
    "\n",
    "print(accuracy_nb_test)\n",
    "print(accuracy_nb_train)\n",
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_nb_test))\n",
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_nb_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "patient-greenhouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9876828329484219, 0.9869130100076983, 0.9899923017705927, 0.9838337182448037, 0.9830638953040801, 0.9869130100076983, 0.9899884482094725]\n",
      "[0.9871046384807852, 0.9870404824533265, 0.9865272342336563, 0.9875537306729967, 0.9877461987553731, 0.9871046384807852, 0.9867847061842443]\n",
      "Mean accuracy for test set =  0.9869124594989668\n",
      "Mean accuracy for train set =  0.9871230898944525\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "accuracy_log_test = []\n",
    "accuracy_log_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:      #creating training dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:      #creating testing dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "                \n",
    "    #convert into array\n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    #importing model from sklearn \n",
    "    clf = LogisticRegression(random_state = 0)\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    #predict class\n",
    "    test_pred_y_log = clf.predict(test_data_xn)\n",
    "    train_pred_y_log = clf.predict(train_data_xn)\n",
    "    \n",
    "    #calculating and appending accuracies\n",
    "    acc1_log = accuracy_score(test_data_yn, test_pred_y_log)\n",
    "    accuracy_log_test.append(acc1_log)\n",
    "    \n",
    "    acc2_log = accuracy_score(train_data_yn, train_pred_y_log)\n",
    "    accuracy_log_train.append(acc2_log)\n",
    "\n",
    "print(accuracy_log_test)\n",
    "print(accuracy_log_train)\n",
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_log_test))\n",
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_log_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "numerous-syndrome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9888375673595073, 0.9880677444187836, 0.9899923017705927, 0.9872979214780601, 0.9849884526558892, 0.9896073903002309, 0.9899884482094725]\n",
      "[0.9888368512221724, 0.9888368512221724, 0.9882594469750433, 0.9887085391672548, 0.9890293193045486, 0.9888368512221724, 0.9885168078008725]\n",
      "Mean accuracy for test set =  0.9883971180275052\n",
      "Mean accuracy for train set =  0.9887178095591767\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "accuracy_svm_test = []\n",
    "accuracy_svm_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:      #creating training dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:      #creating testing dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "                \n",
    "    #convert into array\n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    #importing model from sklearn\n",
    "    clf = SVC(kernel = 'rbf')\n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    #predict class\n",
    "    test_pred_y_svm = clf.predict(test_data_xn)\n",
    "    train_pred_y_svm = clf.predict(train_data_xn)\n",
    "\n",
    "    #calculating and appending accuracies\n",
    "    acc1_svm = accuracy_score(test_data_yn, test_pred_y_svm)\n",
    "    accuracy_svm_test.append(acc1_svm)\n",
    "    \n",
    "    acc2_svm = accuracy_score(train_data_yn, train_pred_y_svm)\n",
    "    accuracy_svm_train.append(acc2_svm)\n",
    "\n",
    "print(accuracy_svm_test)\n",
    "print(accuracy_svm_train)\n",
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_svm_test))\n",
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_svm_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "\n",
    "accuracy_ann_test = []\n",
    "accuracy_ann_train = []\n",
    "\n",
    "for i in range(7):\n",
    "    test_data = data_g[i]\n",
    "    test_data_x = []\n",
    "    test_data_y = []\n",
    "    train_data_x = []\n",
    "    train_data_y = []\n",
    "    for j in range(7):\n",
    "        if j!=i:      #creating training dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                train_data_x.append(data_g[j][w][:10])\n",
    "                train_data_y.append(data_g[j][w][10])\n",
    "        elif j == i:      #creating testing dataset\n",
    "            for w in range(len(data_g[j])):\n",
    "                test_data_x.append(data_g[j][w][:10])\n",
    "                test_data_y.append(data_g[j][w][10])\n",
    "                \n",
    "    #convert into array\n",
    "    test_data_xn = np.array(test_data_x)\n",
    "    train_data_xn = np.array(train_data_x)\n",
    "    test_data_yn = np.array(test_data_y)\n",
    "    train_data_yn = np.array(train_data_y)\n",
    "    \n",
    "    #importing model from sklearn\n",
    "    clf = MLPClassifier(hidden_layer_sizes = (10, 10, 10, 10,), max_iter = 1000, activation = 'logistic', solver = 'adam', \n",
    "                        random_state = 1)\n",
    "    \n",
    "    clf.fit(train_data_xn, train_data_yn)\n",
    "    \n",
    "    #predict class\n",
    "    test_pred_y_ann = clf.predict(test_data_xn)\n",
    "    train_pred_y_ann = clf.predict(train_data_xn)\n",
    "    \n",
    "    #calculating and appending accuracies\n",
    "    acc1_ann = accuracy_score(test_data_yn, test_pred_y_ann)\n",
    "    accuracy_ann_test.append(acc1_ann)\n",
    "    \n",
    "    acc2_ann = accuracy_score(train_data_yn, train_pred_y_ann)\n",
    "    accuracy_ann_train.append(acc2_ann)\n",
    "\n",
    "\n",
    "print(accuracy_ann_test)\n",
    "print(accuracy_ann_train)\n",
    "print(\"Mean accuracy for test set = \", statistics.mean(accuracy_ann_test))\n",
    "print(\"Mean accuracy for train set = \", statistics.mean(accuracy_ann_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 10))\n",
    "plt.boxplot([accuracy_fl_test, accuracy_lp_test, accuracy_nb_test, accuracy_log_test, accuracy_svm_test, accuracy_ann_test])\n",
    "\n",
    "plt.text(0.75, 0.97, \"Fisher Linear Discriminant\")\n",
    "plt.text(0.80, statistics.mean(accuracy_fl_test) + 0.0006, \"Mean: \" + str(round(statistics.mean(accuracy_fl_test), 5)))\n",
    "\n",
    "plt.text(1.75, 0.99, \"Linear Perceptron\")\n",
    "plt.text(1.82, statistics.mean(accuracy_lp_test) + 0.0001, \"Mean: \" + str(round(statistics.mean(accuracy_lp_test), 5)))\n",
    "\n",
    "plt.text(2.70, 0.97, \"Naive Bayes\")\n",
    "plt.text(2.82, statistics.mean(accuracy_nb_test) + 0.0002, \"Mean: \" + str(round(statistics.mean(accuracy_nb_test), 5)))\n",
    "\n",
    "plt.text(3.85, 0.97, \"Logistic Regression\")\n",
    "plt.text(3.80, statistics.mean(accuracy_log_test) + 0.001, \"Mean: \" + str(round(statistics.mean(accuracy_log_test), 5)))\n",
    "\n",
    "plt.text(4.68, 0.97, \"Support Vector Machine\")\n",
    "plt.text(4.80, statistics.mean(accuracy_svm_test) + 0.001, \"Mean: \" + str(round(statistics.mean(accuracy_svm_test), 5)))\n",
    "\n",
    "plt.text(5.68, 0.97, \"Artificial Neural Networks\")\n",
    "plt.text(5.80, statistics.mean(accuracy_ann_test), \"Mean: \" + str(round(statistics.mean(accuracy_ann_test), 5)))\n",
    "\n",
    "#plt.savefig(\"boxPlot.jpeg\")\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-optimum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
